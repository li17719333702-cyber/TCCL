"""
CWRUè½´æ‰¿æ•…éšœæ•°æ®é›† - æ”¹è¿›ç‰ˆ

æ”¯æŒä¸‰ç§æ ‡å‡†åŒ–æ¨¡å¼ï¼š
1. mode='full': ä½¿ç”¨å…¨æ•°æ®é›†ç»Ÿè®¡é‡æ ‡å‡†åŒ–ï¼ˆæ¨èç”¨äºæ— ç›‘ç£èšç±»ï¼‰
2. mode='train': è®­ç»ƒæ¨¡å¼ï¼Œè®¡ç®—å¹¶ä¿å­˜ç»Ÿè®¡é‡
3. mode='test': æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨è®­ç»ƒé›†çš„ç»Ÿè®¡é‡

æ ‡å‡†åŒ–ç­–ç•¥ï¼š
- æ•°æ®é›†çº§åˆ«çš„Z-scoreæ ‡å‡†åŒ–
- ä¿ç•™ä¸åŒæ–‡ä»¶é—´çš„æŒ¯å¹…å·®å¼‚ï¼ˆé‡è¦çš„æ•…éšœç‰¹å¾ï¼‰
- ç¡®ä¿è®­ç»ƒ-æµ‹è¯•ä¸€è‡´æ€§ï¼Œé¿å…æ•°æ®æ³„éœ²
"""

import torch
from torch.utils.data import Dataset
import scipy.io as sio
import numpy as np
from tqdm import tqdm
from pathlib import Path
from typing import Optional, Dict


def load_cwru_signal(file_path: str) -> np.ndarray:
    """
    ä»CWRUæ ¼å¼çš„.matæ–‡ä»¶ä¸­åŠ è½½é©±åŠ¨ç«¯(DE)çš„æŒ¯åŠ¨ä¿¡å·
    è‡ªåŠ¨æŸ¥æ‰¾ä»¥ "_DE_time" æˆ– "_FE_time" ç»“å°¾çš„é”®
    """
    try:
        mat_contents = sio.loadmat(file_path)
        signal_key = None
        
        # ä¼˜å…ˆæŸ¥æ‰¾é©±åŠ¨ç«¯ä¿¡å·
        for key in mat_contents.keys():
            if key.endswith("_DE_time"):
                signal_key = key
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™æŸ¥æ‰¾é£æ‰‡ç«¯ä¿¡å·ä½œä¸ºå¤‡ç”¨
        if not signal_key:
            for key in mat_contents.keys():
                if key.endswith("_FE_time"):
                    signal_key = key
                    break
        
        if signal_key:
            return mat_contents[signal_key].flatten()
        else:
            print(f"è­¦å‘Š: åœ¨æ–‡ä»¶ {Path(file_path).name} ä¸­æ‰¾ä¸åˆ° _DE_time æˆ– _FE_time é”®")
            return np.array([])
    
    except Exception as e:
        print(f"è­¦å‘Š: åŠ è½½æ–‡ä»¶ {Path(file_path).name} å¤±è´¥: {e}")
        return np.array([])


class CWRUDataset(Dataset):
    """CWRUè½´æ‰¿æ•…éšœæ•°æ®é›†"""
    
    LABEL_MAP = {
        'normal': 0,
        'ball': 1,          # æ»šåŠ¨ä½“æ•…éšœ (B)
        'inner_race': 2,    # å†…åœˆæ•…éšœ (IR)
        'outer_race': 3     # å¤–åœˆæ•…éšœ (OR)
    }
    
    def __init__(self, 
                 root_dir: str, 
                 window_size: int = 1024, 
                 step_size: int = 512, 
                 augmentor=None,
                 normalization_stats: Optional[Dict] = None,
                 mode: str = 'full'):
        """
        åˆå§‹åŒ–CWRUæ•°æ®é›†
        
        å‚æ•°:
            root_dir: æ•°æ®é›†æ ¹ç›®å½•ï¼ŒåŒ…å«.matæ–‡ä»¶
            window_size: æ»‘åŠ¨çª—å£å¤§å°
            step_size: æ»‘åŠ¨çª—å£æ­¥é•¿
            augmentor: æ•°æ®å¢å¼ºå™¨ï¼ˆç”¨äºå¯¹æ¯”å­¦ä¹ ï¼‰
            normalization_stats: é¢„å…ˆè®¡ç®—çš„ç»Ÿè®¡é‡ {'mean': ..., 'std': ...}
            mode: æ¨¡å¼é€‰æ‹©
                - 'full': å…¨æ•°æ®é›†æ¨¡å¼ï¼Œè®¡ç®—å¹¶ä½¿ç”¨å…¨éƒ¨æ•°æ®çš„ç»Ÿè®¡é‡ï¼ˆæ¨èç”¨äºæ— ç›‘ç£èšç±»ï¼‰
                - 'train': è®­ç»ƒæ¨¡å¼ï¼Œè®¡ç®—å¹¶ä¿å­˜ç»Ÿè®¡é‡
                - 'test': æµ‹è¯•æ¨¡å¼ï¼Œå¿…é¡»æä¾›normalization_stats
        """
        self.root_dir = Path(root_dir)
        self.window_size = window_size
        self.step_size = step_size
        self.augmentor = augmentor
        self.mode = mode
        self.class_names = {v: k for k, v in self.LABEL_MAP.items()}
        
        self.samples = []
        self.labels = []
        
        # æ ‡å‡†åŒ–ç­–ç•¥ï¼šæ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„ç»Ÿè®¡é‡è®¡ç®—æ–¹å¼
        if mode == 'full':
            print(f"[CWRU - å…¨æ•°æ®é›†æ¨¡å¼] ç›®å½•: {self.root_dir}")
            self.dataset_mean, self.dataset_std = self._compute_dataset_stats()
            print(f"æ•°æ®é›†ç»Ÿè®¡é‡: Î¼={self.dataset_mean:.6f}, Ïƒ={self.dataset_std:.6f}")
        elif mode == 'train':
            print(f"[CWRU - è®­ç»ƒé›†æ¨¡å¼] ç›®å½•: {self.root_dir}")
            self.dataset_mean, self.dataset_std = self._compute_dataset_stats()
            print(f"è®­ç»ƒé›†ç»Ÿè®¡é‡: Î¼={self.dataset_mean:.6f}, Ïƒ={self.dataset_std:.6f}")
        elif mode == 'test':
            if normalization_stats is None:
                raise ValueError("æµ‹è¯•æ¨¡å¼(mode='test')å¿…é¡»æä¾›normalization_statså‚æ•°")
            print(f"[CWRU - æµ‹è¯•é›†æ¨¡å¼] ç›®å½•: {self.root_dir}")
            self.dataset_mean = normalization_stats['mean']
            self.dataset_std = normalization_stats['std']
            print(f"ä½¿ç”¨è®­ç»ƒé›†ç»Ÿè®¡é‡: Î¼={self.dataset_mean:.6f}, Ïƒ={self.dataset_std:.6f}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}ï¼Œè¯·ä½¿ç”¨ 'full', 'train' æˆ– 'test'")
        
        self._load_data()
    
    def _compute_dataset_stats(self) -> tuple:
        """è®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„å…¨å±€ç»Ÿè®¡é‡ï¼ˆå‡å€¼å’Œæ ‡å‡†å·®ï¼‰"""
        mat_files = sorted(list(self.root_dir.glob('*.mat')))
        if not mat_files:
            raise FileNotFoundError(f"åœ¨ {self.root_dir} ä¸­æœªæ‰¾åˆ°.matæ–‡ä»¶")
        
        print(f"æ‰«æ {len(mat_files)} ä¸ªæ–‡ä»¶ï¼Œè®¡ç®—å…¨å±€ç»Ÿè®¡é‡...")
        all_signals = []
        
        for file_path in tqdm(mat_files, desc="æ”¶é›†æ•°æ®", leave=False):
            signal = load_cwru_signal(str(file_path))
            if signal.size > 0:
                all_signals.append(signal)
        
        if not all_signals:
            raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶")
        
        # åˆå¹¶æ‰€æœ‰ä¿¡å·å¹¶è®¡ç®—ç»Ÿè®¡é‡
        all_data = np.concatenate(all_signals)
        mean = all_data.mean()
        std = all_data.std() + 1e-6  # é˜²æ­¢é™¤é›¶
        
        return mean, std
    
    def _get_label_from_filename(self, filename: str) -> int:
        """æ ¹æ®æ–‡ä»¶åè§£ææ ‡ç­¾"""
        name = filename.lower()
        # å…³é”®è¯åŒ¹é…é¡ºåºå¾ˆé‡è¦ï¼Œä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„é•¿å­—ç¬¦ä¸²
        if 'normal' in name:
            return self.LABEL_MAP['normal']
        elif 'ir' in name:
            return self.LABEL_MAP['inner_race']
        elif 'or' in name:
            return self.LABEL_MAP['outer_race']
        elif 'b' in name:
            return self.LABEL_MAP['ball']
        return -1
    
    def _load_data(self):
        """åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†"""
        mat_files = sorted(list(self.root_dir.glob('*.mat')))
        print(f"åŠ è½½ {len(mat_files)} ä¸ª.matæ–‡ä»¶...")
        
        for file_path in tqdm(mat_files, desc=f"åŠ è½½æ•°æ®({self.mode})", leave=False):
            label = self._get_label_from_filename(file_path.name)
            if label == -1:
                print(f"è­¦å‘Š: æ— æ³•è¯†åˆ«æ–‡ä»¶ {file_path.name} çš„æ ‡ç­¾ï¼Œå·²è·³è¿‡")
                continue
            
            signal = load_cwru_signal(str(file_path))
            if signal.size < self.window_size:
                print(f"è­¦å‘Š: æ–‡ä»¶ {file_path.name} ä¿¡å·è¿‡çŸ­ ({signal.size})ï¼Œå·²è·³è¿‡")
                continue
            
            # ä½¿ç”¨æ•°æ®é›†çº§åˆ«çš„ç»Ÿè®¡é‡è¿›è¡Œæ ‡å‡†åŒ–
            num_windows = (len(signal) - self.window_size) // self.step_size + 1
            for i in range(num_windows):
                start_idx = i * self.step_size
                segment = signal[start_idx: start_idx + self.window_size]
                # å…³é”®ï¼šä½¿ç”¨æ•°æ®é›†ç»Ÿè®¡é‡ï¼Œè€Œéæ–‡ä»¶æˆ–çª—å£ç»Ÿè®¡é‡
                segment = (segment - self.dataset_mean) / self.dataset_std
                self.samples.append(segment)
                self.labels.append(label)
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"æ•°æ®åŠ è½½å®Œæˆï¼å…±ç”Ÿæˆ {len(self.samples)} ä¸ªæ ·æœ¬")
        label_counts = {name: self.labels.count(idx) for name, idx in self.LABEL_MAP.items()}
        print(f"å„ç±»åˆ«æ ·æœ¬æ•°: {label_counts}")
    
    def get_normalization_stats(self) -> Dict:
        """è¿”å›æ ‡å‡†åŒ–ç»Ÿè®¡é‡ï¼Œä¾›æµ‹è¯•é›†ä½¿ç”¨"""
        return {
            'mean': self.dataset_mean,
            'std': self.dataset_std
        }
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int):
        signal = torch.from_numpy(self.samples[idx]).float().unsqueeze(0)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        
        if self.augmentor:
            view1 = self.augmentor(signal)
            view2 = self.augmentor(signal)
            return view1, view2, label
        
        return signal, signal, label

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================
if __name__ == '__main__':
    DATA_ROOT = r'E:\AI\CWRU-dataset-main\48k007'
    
    data_path = Path(DATA_ROOT)
    if not data_path.exists():
        print(f"âš ï¸  ç¤ºä¾‹ç›®å½• '{DATA_ROOT}' ä¸å­˜åœ¨")
        print("è¯·ä¿®æ”¹ DATA_ROOT ä¸ºä½ çš„å®é™…æ•°æ®è·¯å¾„")
        exit(0)
    
    print("=" * 80)
    print("CWRUæ•°æ®é›† - å…¨æ•°æ®é›†æ¨¡å¼ç¤ºä¾‹")
    print("=" * 80)
    
    # å…¨æ•°æ®é›†æ¨¡å¼
    dataset = CWRUDataset(
        root_dir=DATA_ROOT,
        window_size=1024,
        step_size=512,
        mode='full'
    )
    
    print(f"\nâœ… æ•°æ®é›†åŠ è½½æˆåŠŸï¼")
    print(f"   æ€»æ ·æœ¬æ•°: {len(dataset)}")
    print(f"   ç±»åˆ«æ˜ å°„: {dataset.LABEL_MAP}")
    
    # æŸ¥çœ‹ä¸€ä¸ªæ ·æœ¬
    sample_signal, _, sample_label = dataset[0]
    print(f"   æ ·æœ¬å½¢çŠ¶: {sample_signal.shape}")
    print(f"   æ ·æœ¬æ ‡ç­¾: {sample_label.item()} ({dataset.class_names[sample_label.item()]})")
    
    print("\nğŸ’¡ æ›´å¤šä½¿ç”¨ç¤ºä¾‹è¯·å‚è€ƒ datasets/mfpt.py")
    print("=" * 80)



